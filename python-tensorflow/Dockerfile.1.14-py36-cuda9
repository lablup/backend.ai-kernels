# Lablup/Python-TensorFlow 1.14 Python 3.6

FROM lablup/common-tensorflow:1.14-py36 as tf-binary

FROM lablup/common-base:19.06-py36-cuda9
MAINTAINER Mario Cho "m.cho@lablup.com"

# Install ipython kernelspec
RUN python3 -m ipykernel install --display-name "TensorFlow 1.14 on Python 3.6 (CUDA 9.0)" && \
    cat /usr/local/share/jupyter/kernels/python3/kernel.json

COPY --from=tf-binary /tmp/tensorflow_pkg/tensorflow-*.whl /tmp

RUN python3 -m pip install --no-cache-dir wheel /tmp/*.whl && \
    python3 -m pip install --no-cache-dir keras && \
    python3 -m pip install --no-cache-dir keras_applications && \
    python3 -m pip install --no-cache-dir keras_preprocessing && \
    python3 -m pip install --no-cache-dir tensorflow-hub==0.5.0 && \
    python3 -m pip install --no-cache-dir tf2onnx && \
    rm -rf /root/.cache && \
    rm -f /tmp/*.whl

# for apt-get installation using /tmp
RUN mkdir -p /tmp && \
    chown root:root /tmp && \
    chmod 1777 /tmp
    
# Backend.AI specifics
LABEL ai.backend.kernelspec="1" \
      ai.backend.envs.corecount="OPENBLAS_NUM_THREADS,OMP_NUM_THREADS,NPROC" \
      ai.backend.features="batch query uid-match user-input" \
      ai.backend.base-distro="ubuntu18.04" \
      ai.backend.resource.min.cpu="1" \
      ai.backend.resource.min.mem="1g" \
      ai.backend.resource.min.cuda.device=1 \
      ai.backend.resource.min.cuda.shares=0.1 \
      ai.backend.runtime-type="python" \
      ai.backend.runtime-path="/usr/local/bin/python" \
      ai.backend.service-ports="ipython:pty:3000,jupyter:http:8080,jupyterlab:http:8090"

WORKDIR /home/work
# vim: ft=dockerfile