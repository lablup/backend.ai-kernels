FROM nvcr.io/nvidia/pytorch:19.07-py3
# NVIDIA PyTorch with Python 3.6 (CONDA)

ENV PYTHONUNBUFFERED=1 \
    PATH=/opt/conda/bin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:$PATH \
    LANG=C.UTF-8

# ipython/jupyter is already installed in the Anaconda Python installed at /opt/conda.
RUN /opt/conda/bin/python3 -m pip install jupyterlab

# Install ipython kernelspec
RUN /opt/conda/bin/python3 -m ipykernel install \
        --prefix=/opt/conda/ \
        --display-name "Python 3.6 CONDA (NGC/PyTorch 19.07) on Backend.AI" && \
    cat /opt/conda/share/jupyter/kernels/python3/kernel.json

# for apt-get installation using /tmp
RUN mkdir -p /tmp && \
    chown root:root /tmp && \
    chmod 1777 /tmp

ARG CODE_SERVER_VERSION=1.1156-vsc1.33.1

COPY ./code-server.${CODE_SERVER_VERSION}.tar.xz /tmp/code-server.tar.xz
# TODO: Bundle ms-python extension with code-server when code-server v2 is released.
# COPY code-server.ext.tar.gz /tmp/code-server.ext.tar.gz
RUN tar xvJf /tmp/code-server.tar.xz -C /usr/local/bin

# Backend.AI specifics
COPY policy.yml /etc/backend.ai/jail/policy.yml
LABEL ai.backend.kernelspec="1" \
      ai.backend.envs.corecount="OPENBLAS_NUM_THREADS,OMP_NUM_THREADS,NPROC" \
      ai.backend.features="batch uid-match" \
      ai.backend.accelerators="cuda" \
      ai.backend.resource.min.cpu="1" \
      ai.backend.resource.min.mem="1g" \
      ai.backend.resource.min.cuda.device=1 \
      ai.backend.resource.min.cuda.shares=0.1 \
      ai.backend.base-distro="ubuntu16.04" \
      ai.backend.runtime-type="python" \
      ai.backend.runtime-path="/opt/conda/bin/python3" \
      ai.backend.service-ports="ipython:pty:3000,jupyter:http:8080,jupyterlab:http:8090;vscode:http:8180"

# vim: ft=dockerfile
